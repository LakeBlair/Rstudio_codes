---
title: "HW03"
author: "Jiawei Hao, hjiawei"
date: "Due 2021-09-21 at midnight"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(288942)
library(tidyverse)
```

## Caching

Now that we are generating large numbers of random numbers, it can be useful to save those results in between Knit-ings of the `.Rmd` file. You'll notice that several chunks below have the option `cache = TRUE` turned on. The first time you knit this document those chunks will be run and the results saved. Provided you do not change the code in those chunks, the they will not be re-run in the future, saving you time.

Feel free to turn on caching for your own work, but some care is needed to make sure that if a cached chunk depends on results from an earlier chunk your will need to force rebuilding it by setting `cache.rebuild = TRUE` temporarily. 

## Problem 1 (3 pts)

Use Monte Carlo integration with 10,000 samples to get a 95\% confidence interval for each of the following integrals. R's uniform random number generator can be found at `runif`. Other built in distributions can be found under the help page for `Distributions`.

```{r}
k <- 10000 # often a good idea to define variables to hold things like the number of samples
```

To create the confidence interval, you can use R's `t.test` function.

Here's an example to estimate the Gamma function from class $\theta = \int_{0}^1 (\log(1/x))^3 dx$.

```{r cache = TRUE}
us <- runif(k)
gus <- log(1/us)^3
mean(gus) # estimate
t.test(gus, conf.level = 0.95)$conf.int
```
## Part (a) (1 pt)

$$\int_0^1 x^2 \, d x$$
```{r cache = TRUE}
k1 <- 10000
us1 <- runif(k)
func <- us1^2
mean(func)
t.test(func, conf.level = 0.95)$conf.int
```

## Part (b) (1 pt)

$$\int_0^1 \int_{-2}^{2} x^2 \cos (xy) \, dx \, dy = \int_0^1 \int_{-2}^{2} x^2 \cos (xy) \frac{f(x,y)}{f(x,y)} \, dx \, dy = E\left(\frac{X^2 \cos(XY)}{f(X,Y)}\right) $$
```{r}
x <- 10000
y <- 10000
x1 <- runif(x,-2,2)
y1 <- runif(y,0,1)
func1 <- x1^2*cos(x1)
mean(func1)
```
## Part (c) (1 pts)

$$\int_{-\infty}^\infty e^{-|x|} \, dx$$
Hint: See the `Distributions` help page in R for a list of random number generators built into R. What distribution is defined on $(-\infty, \infty)$?
```{r}
x2 <- 10000
g <- function(x){exp(-abs(x))}
h <- function(x){g(x)/dnorm(x)}
xval <- h(rnorm(x2))
mean(xval)
t.test(xval, conf.level = 0.95)$conf.int
```

## Problem 2 (3 pts)

Read sections 1 to 3 of the paper "Does your iPod *Really* Play Favorites?" (Feel free to read the entire paper if you wish, but we'll concentrate only the first three sections.) 

### Part (a) (1 pt)

Briefly summarize the research question and methods employed in this paper. What questions were the authors trying to answer? What methods did they use?

### Part (b) (1 pts)

Using the `tracks` data from the previous homework, we will recreate a similar analysis to the paper.

```{r}
load("tracks.rda")
ggplot(data = tracks, aes(x = duration_ms)) + geom_density()
```

In a randomly selected shuffle of 120 songs, what is the expected value of the longest duration song (in milliseconds)? In other words, if $X_1, \ldots, X_n$ is a random sample song lengths, find $E(\max_i X_i)$. Using 10,000 Monte Carlo replications of samples of size 120,  provide a 99% confidence interval for this value. The `replicate` and `sample_n` functions will be helpful.

```{r}
index <- sample(tracks$duration_ms,120)
k <- 10000
sample_vec <- replicate(k, max(sample(tracks$duration_ms,120)))
mean(sample_vec)
t.test(sample_vec, conf.level = 0.99)$conf.int
```
### Part (c) (1 pts)

In a shuffle of 120 songs, estimate the probability that at least ten songs exceed 5 minutes in length. Again use 10,000 Monte Carlo replications of samples of 120 songs. Be sure to report the proper type of 99% confidence interval. (Hint for faster computation: you want to decide if each song is long before sampling rather than in the sample.)
```{r}
g <- function(x){
    count <- 0
    for (item in x){
        if(item > 300000){
            count <- count + 1
        }
    }
    atleast10 <- (count >= 10)
    return (atleast10)
}
sample_vec <- replicate(k, sample(tracks$duration_ms,120) %>% g)
sum(sample_vec)
mean(sample_vec)
binom.test(sum(sample_vec), k, conf.level = 0.99)$conf.int

```
## Question 3 (4 pts)

Consider the distribution given by the density:

$$f(x) = \frac{1}{\theta}, x \in [0, \theta], \theta > 0$$

We will see later that two estimators for $\theta$ are:

- Method of Moments: $\tilde \theta = 2 \bar X$
- Maximum Likelihood $\hat \theta = \max_{i} X_i$

We will explore the duality between estimators and test statistics.

### Part (a) (1 pt)

Suppose we wish to test the hypothesis that $\theta = 50$ against the alternative that $\theta = 51$. We will suppose we have a sample size of $n = 56$ observations. 

$$H_0: \theta = 50 \text{ vs } H_1: \theta = 51$$

As test statistics, we can use the estimators given above.

Suppose the true $\theta = 50$. Find the null distribution for $\tilde \theta$ (method of moments) under when $\theta = 50$ and the alternative distribution when $\theta = 51$. Use 10,000 Monte Carlo replications (i.e., 10,000 samples of 56 observations) .

Find a rejection region of the form $\tilde \theta > c$ such that $P(\tilde \theta > c \mid H_0) \le 0.05$. Find the power of this region when $\theta = 51$. 

Here's some code to get you started:

```{r, cache = TRUE}
null_samples <- data.frame(replicate(10000, { runif(56, min = 0, max = 50)}))
alt_samples  <- data.frame(replicate(10000, { runif(56, min = 0, max = 51)}))

test_null <- map_dbl(null_samples, ~2*mean(.x))
test_alt <- map_dbl(alt_samples, ~2*mean(.x))

reject_region <- c(quantile(test_null,0.95))
paste("rejection region is theta > ",reject_region)
power <- mean(test_alt > reject_region)

paste("power is ",power)
```  

### Part (b) (1 pt)

Repeat this process using $\hat \theta$ (the MLE statistic). Which statistic has greater power?
```{r, cache = TRUE}
null_samples <- data.frame(replicate(10000, { runif(56, min = 0, max = 50)}))
alt_samples  <- data.frame(replicate(10000, { runif(56, min = 0, max = 51)}))

test_null <- map_dbl(null_samples, ~max(.x))
test_alt <- map_dbl(alt_samples, ~max(.x))

reject_region <- c(quantile(test_null,0.95))
power <- mean(test_alt > reject_region)

paste("power is ",power)
```  
$\hat \theta$ has greater power  
### Part (c) (1 pt)

Create a power curve for each method evaluated at the following alternative distributions. Save some time, feel free to only use 1000 samples (of 56 observations each) per alternative hypothesis.

```{r}
theta_power <- 51:80
power_mean_data <- c()
power_max_data <- c()

for (p in theta_power){
null_samples_mean <- data.frame(replicate(1000, { runif(56, min = 0, max = 50)}))
alt_samples_mean  <- data.frame(replicate(1000, { runif(56, min = 0, max = p)}))

test_null <- map_dbl(null_samples_mean, ~2*mean(.x))
test_alt <- map_dbl(alt_samples_mean, ~2*mean(.x))

reject_region <- c(quantile(test_null,0.95))
pow <- mean(test_alt > reject_region)

power_mean_data <- append(power_mean_data,pow)
}
for (p in theta_power){
null_samples_max <- data.frame(replicate(1000, { runif(56, min = 0, max = 50)}))
alt_samples_max  <- data.frame(replicate(1000, { runif(56, min = 0, max = p)}))

test_null <- map_dbl(null_samples_max, ~max(.x))
test_alt <- map_dbl(alt_samples_max, ~max(.x))

reject_region <- c(quantile(test_null,0.95))
pow <- mean(test_alt > reject_region)

power_max_data <- append(power_max_data,pow)
}

df_mle <- data.frame(theta = theta_power, power = power_mean_data, statistic = "MLE")
df_mom <- data.frame(theta = theta_power, power = power_max_data, statistic = "MoM")
df_both <- rbind(df_mle,df_mom)
ggplot(data = df_both, aes(x = theta, y = power, color = statistic)) + geom_line()
```

How large does $\theta$ have to be to achieve $>80$% power for each of the methods?    

For moment method, $\theta >= 61$ when power $>80%.  
For maximum likelihood method, $\theta >= 52$ when power $>80%  

### Part (d) (1 pt)
```{r echo = FALSE}
fish <- structure(list(Obs = 1:159, Species = c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L), Weight = c(242, 290, 340, 
363, 430, 450, 500, 390, 450, 500, 475, 500, 500, NA, 600, 600, 
700, 700, 610, 650, 575, 685, 620, 680, 700, 725, 720, 714, 850, 
1000, 920, 955, 925, 975, 950, 270, 270, 306, 540, 800, 1000, 
40, 69, 78, 87, 120, 0, 110, 120, 150, 145, 160, 140, 160, 169, 
161, 200, 180, 290, 272, 390, 55, 60, 90, 120, 150, 140, 170, 
145, 200, 273, 300, 6.7, 7.5, 7, 9.7, 9.8, 8.7, 10, 9.9, 9.8, 
12.2, 13.4, 12.2, 19.7, 19.9, 200, 300, 300, 300, 430, 345, 456, 
510, 540, 500, 567, 770, 950, 1250, 1600, 1550, 1650, 5.9, 32, 
40, 51.5, 70, 100, 78, 80, 85, 85, 110, 115, 125, 130, 120, 120, 
130, 135, 110, 130, 150, 145, 150, 170, 225, 145, 188, 180, 197, 
218, 300, 260, 265, 250, 250, 300, 320, 514, 556, 840, 685, 700, 
700, 690, 900, 650, 820, 850, 900, 1015, 820, 1100, 1000, 1100, 
1000, 1000), Length1 = c(23.2, 24, 23.9, 26.3, 26.5, 26.8, 26.8, 
27.6, 27.6, 28.5, 28.4, 28.7, 29.1, 29.5, 29.4, 29.4, 30.4, 30.4, 
30.9, 31, 31.3, 31.4, 31.5, 31.8, 31.9, 31.8, 32, 32.7, 32.8, 
33.5, 35, 35, 36.2, 37.4, 38, 23.6, 24.1, 25.6, 28.5, 33.7, 37.3, 
12.9, 16.5, 17.5, 18.2, 18.6, 19, 19.1, 19.4, 20.4, 20.5, 20.5, 
21, 21.1, 22, 22, 22.1, 23.6, 24, 25, 29.5, 13.5, 14.3, 16.3, 
17.5, 18.4, 19, 19, 19.8, 21.2, 23, 24, 9.3, 10, 10.1, 10.4, 
10.7, 10.8, 11.3, 11.3, 11.4, 11.5, 11.7, 12.1, 13.2, 13.8, 30, 
31.7, 32.7, 34.8, 35.5, 36, 40, 40, 40.1, 42, 43.2, 44.8, 48.3, 
52, 56, 56, 59, 7.5, 12.5, 13.8, 15, 15.7, 16.2, 16.8, 17.2, 
17.8, 18.2, 19, 19, 19, 19.3, 20, 20, 20, 20, 20, 20.5, 20.5, 
20.7, 21, 21.5, 22, 22, 22.6, 23, 23.5, 25, 25.2, 25.4, 25.4, 
25.4, 25.9, 26.9, 27.8, 30.5, 32, 32.5, 34, 34, 34.5, 34.6, 36.5, 
36.5, 36.6, 36.9, 37, 37, 37.1, 39, 39.8, 40.1, 40.2, 41.1), 
    Lenght2 = c(25.4, 26.3, 26.5, 29, 29, 29.7, 29.7, 30, 30, 
    30.7, 31, 31, 31.5, 32, 32, 32, 33, 33, 33.5, 33.5, 34, 34, 
    34.5, 35, 35, 35, 35, 36, 36, 37, 38.5, 38.5, 39.5, 41, 41, 
    26, 26.5, 28, 31, 36.4, 40, 14.1, 18.2, 18.8, 19.8, 20, 20.5, 
    20.8, 21, 22, 22, 22.5, 22.5, 22.5, 24, 23.4, 23.5, 25.2, 
    26, 27, 31.7, 14.7, 15.5, 17.7, 19, 20, 20.7, 20.7, 21.5, 
    23, 25, 26, 9.8, 10.5, 10.6, 11, 11.2, 11.3, 11.8, 11.8, 
    12, 12.2, 12.4, 13, 14.3, 15, 32.3, 34, 35, 37.3, 38, 38.5, 
    42.5, 42.5, 43, 45, 46, 48, 51.7, 56, 60, 60, 63.4, 8.4, 
    13.7, 15, 16.2, 17.4, 18, 18.7, 19, 19.6, 20, 21, 21, 21, 
    21.3, 22, 22, 22, 22, 22, 22.5, 22.5, 22.7, 23, 23.5, 24, 
    24, 24.6, 25, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28, 28.7, 
    30, 32.8, 34.5, 35, 36.5, 36, 37, 37, 39, 39, 39, 40, 40, 
    40, 40, 42, 43, 43, 43.5, 44), Lenght3 = c(30, 31.2, 31.1, 
    33.5, 34, 34.7, 34.5, 35, 35.1, 36.2, 36.2, 36.2, 36.4, 37.3, 
    37.2, 37.2, 38.3, 38.5, 38.6, 38.7, 39.5, 39.2, 39.7, 40.6, 
    40.5, 40.9, 40.6, 41.5, 41.6, 42.6, 44.1, 44, 45.3, 45.9, 
    46.5, 28.7, 29.3, 30.8, 34, 39.6, 43.5, 16.2, 20.3, 21.2, 
    22.2, 22.2, 22.8, 23.1, 23.7, 24.7, 24.3, 25.3, 25, 25, 27.2, 
    26.7, 26.8, 27.9, 29.2, 30.6, 35, 16.5, 17.4, 19.8, 21.3, 
    22.4, 23.2, 23.2, 24.1, 25.8, 28, 29, 10.8, 11.6, 11.6, 12, 
    12.4, 12.6, 13.1, 13.1, 13.2, 13.4, 13.5, 13.8, 15.2, 16.2, 
    34.8, 37.8, 38.8, 39.8, 40.5, 41, 45.5, 45.5, 45.8, 48, 48.7, 
    51.2, 55.1, 59.7, 64, 64, 68, 8.8, 14.7, 16, 17.2, 18.5, 
    19.2, 19.4, 20.2, 20.8, 21, 22.5, 22.5, 22.5, 22.8, 23.5, 
    23.5, 23.5, 23.5, 23.5, 24, 24, 24.2, 24.5, 25, 25.5, 25.5, 
    26.2, 26.5, 27, 28, 28.7, 28.9, 28.9, 28.9, 29.4, 30.1, 31.6, 
    34, 36.5, 37.3, 39, 38.3, 39.4, 39.3, 41.4, 41.4, 41.3, 42.3, 
    42.5, 42.4, 42.5, 44.6, 45.2, 45.5, 46, 46.6), Heightpct = c(38.4, 
    40, 39.8, 38, 36.6, 39.2, 41.1, 36.2, 39.9, 39.3, 39.4, 39.7, 
    37.8, 37.3, 40.2, 41.5, 38.8, 38.8, 40.5, 37.4, 38.3, 40.8, 
    39.1, 38.1, 40.1, 40, 40.3, 39.8, 40.6, 44.5, 40.9, 41.1, 
    41.4, 40.6, 37.9, 29.2, 27.8, 28.5, 31.6, 29.7, 28.4, 25.6, 
    26.1, 26.3, 25.3, 28, 28.4, 26.7, 25.8, 23.5, 27.3, 27.8, 
    26.2, 25.6, 27.7, 25.9, 27.6, 25.4, 30.4, 28, 27.1, 41.5, 
    37.8, 37.4, 39.4, 39.7, 36.8, 40.5, 40.4, 40.1, 39.6, 39.2, 
    16.1, 17, 14.9, 18.3, 16.8, 15.7, 16.9, 16.9, 16.7, 15.6, 
    18, 16.5, 18.9, 18.1, 16, 15.1, 15.3, 15.8, 18, 15.6, 16, 
    15, 17, 14.5, 16, 15, 16.2, 17.9, 15, 15, 15.9, 24, 24, 23.9, 
    26.7, 24.8, 27.2, 26.8, 27.9, 24.7, 24.2, 25.3, 26.3, 25.3, 
    28, 26, 24, 26, 25, 23.5, 24.4, 28.3, 24.6, 21.3, 25.1, 28.6, 
    25, 25.7, 24.3, 24.3, 25.6, 29, 24.8, 24.4, 25.2, 26.6, 25.2, 
    24.1, 29.5, 28.1, 30.8, 27.9, 27.7, 27.5, 26.9, 26.9, 26.9, 
    30.1, 28.2, 27.6, 29.2, 26.2, 28.7, 26.4, 27.5, 27.4, 26.8
    ), ` Widthpct` = c(13.4, 13.8, 15.1, 13.3, 15.1, 14.2, 15.3, 
    13.4, 13.8, 13.7, 14.1, 13.3, 12, 13.6, 13.9, 15, 13.8, 13.5, 
    13.3, 14.8, 14.1, 13.7, 13.3, 15.1, 13.8, 14.8, 15, 14.1, 
    14.9, 15.5, 14.3, 14.3, 14.9, 14.7, 13.7, 14.8, 14.5, 15.2, 
    19.3, 16.6, 15, 14, 13.9, 13.7, 14.3, 16.1, 14.7, 14.7, 13.9, 
    15.2, 14.6, 15.1, 13.3, 15.2, 14.1, 13.6, 15.4, 14, 15.4, 
    15.6, 15.3, 14.1, 13.3, 13.5, 13.7, 14.7, 14.2, 14.7, 13.1, 
    14.2, 14.8, 14.6, 9.7, 10, 9.9, 11.5, 10.3, 10.2, 9.8, 8.9, 
    8.7, 10.4, 9.4, 9.1, 13.6, 11.6, 9.7, 11, 11.3, 10.1, 11.3, 
    9.7, 9.5, 9.8, 11.2, 10.2, 10, 10.5, 11.2, 11.7, 9.6, 9.6, 
    11, 16, 13.6, 15.2, 15.3, 15.9, 17.3, 16.1, 15.1, 14.6, 13.2, 
    15.8, 14.7, 16.3, 15.5, 14.5, 15, 15, 15, 17, 15.1, 15.1, 
    15, 14.8, 14.9, 14.6, 15, 15.9, 13.9, 15.7, 14.8, 17.9, 15, 
    15, 15.8, 14.3, 15.4, 15.1, 17.7, 17.5, 20.9, 17.6, 17.6, 
    15.9, 16.2, 18.1, 14.5, 17.8, 16.8, 17, 17.6, 15.6, 15.4, 
    16.1, 16.3, 17.7, 16.3), Sex = c(NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, 1L, 1L, NA, 1L, NA, NA, NA, 1L, 
    NA, NA, NA, NA, 1L, NA, NA, NA, 0L, 0L, NA, 1L, 0L, NA, NA, 
    NA, NA, NA, 0L, NA, NA, NA, NA, NA, NA, NA, 0L, 0L, 0L, 0L, 
    0L, NA, 0L, NA, NA, 0L, NA, NA, 0L, NA, NA, 1L, 1L, 1L, NA, 
    NA, 0L, 0L, NA, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, NA, 0L, NA, NA, NA, 1L, NA, NA, NA, NA, 
    0L, 0L, NA, NA, NA, 0L, 0L, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, 1L, 0L, 0L, NA, NA, NA, 0L, 0L, 0L, NA, NA, 
    NA, NA, NA, NA, 0L, NA, NA, 0L, 0L, NA, 0L, NA, 0L, 0L, NA, 
    NA, 0L, 0L, 0L, 0L, 0L, 0L, NA, NA, 0L, 0L, 0L, 0L, 0L, 0L, 
    0L, 1L, 0L)), class = "data.frame", row.names = c(NA, -159L
)) 
```

This file includes a sample of fish caught by the University of Helsinki, including their lengths. Using the `length1` measurement and a test statistic of your choice, test the hypothesis that Perch (species code 7) are uniformly distributed between 0 and 50cm against the alternative that they are uniform between 0 and 51cm. 
```{r}
fish_len <- c(fish$Length1)

null_samples <- data.frame(replicate(10000, { runif(56, min = 0, max = 50)}))

test_null <- map_dbl(null_samples, ~2*mean(.x))
2345
reject_region <- c(quantile(test_null,0.95))

2*mean(fish_len)>reject_region

paste("we fail to reject null")
```

We fail to reject null